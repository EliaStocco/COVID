{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi dati dei contagi di COVID-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- github : https://github.com/pcm-dpc/COVID-19\n",
    "- datetime: https://pymotw.com/2/datetime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import datetime #import date,datetime\n",
    "import os.path\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropdata(df):\n",
    "    df.drop([\"data\",\"stato\",\"codice_regione\",\"lat\",\"long\",\"note\"],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfile(date):\n",
    "    return directory + tostr(date,es_fmt) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_reg  = \"dpc-covid19-ita-regioni-\"\n",
    "root_prov = \"dpc-covid19-ita-province-\"\n",
    "latest_file = \"https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/\\\n",
    "dati-regioni/dpc-covid19-ita-regioni-latest.csv\"\n",
    "\n",
    "github_fmt = \"%Y%m%d\"\n",
    "es_fmt = \"%Y-%m-%d\"\n",
    "plt_fmt = \"%b %Y\"\n",
    "\n",
    "data_dir = \"data/\"\n",
    "time_series_dir = \"time series/\"\n",
    "reg_dir = \"Regioni/\"\n",
    "prov_dir =\"Province/\"\n",
    "raw_dir = \"raw/\"\n",
    "\n",
    "first_day = datetime.date(year=2020, month=2, day=24)  # 24 febbraio 2020\n",
    "today = datetime.date.today()\n",
    "today = datetime.date(year=today.year, month=today.month,\n",
    "                      day=today.day)  # today\n",
    "one_day = datetime.timedelta(days=1)\n",
    "\n",
    "print(\"first day   :\", first_day)\n",
    "print(\"today       :\", today)\n",
    "print(\"passed days :\", (today - first_day).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostr(date,fmt=github_fmt):\n",
    "    return date.strftime(fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/1392413/calculating-a-directorys-size-using-python/1392549\n",
    "def get_size(start_path = '.',unit=\"bytes\"):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # skip if it is symbolic link\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    if unit == \"bytes\" :\n",
    "        return total_size\n",
    "    elif unit == \"Kb\" or unit == \"Kilobytes\" :\n",
    "        return total_size/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_reg = list( [ 'Abruzzo', 'Basilicata', 'Calabria', 'Campania', 'Emilia-Romagna', 'Friuli Venezia Giulia', 'Lazio', \\\n",
    "             'Liguria', 'Lombardia', 'Marche', 'Molise', 'P.A. Bolzano', 'P.A. Trento', 'Piemonte', 'Puglia', \\\n",
    "             'Sardegna', 'Sicilia', 'Toscana', 'Umbria', \"Valle d'Aosta\", 'Veneto' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impostazione per sovrascrivere i file\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "directory = data_dir + reg_dir + raw_dir\n",
    "\n",
    "#\n",
    "N = (today - first_day).days\n",
    "k=0\n",
    "for i in range(N+1):\n",
    "    date      = first_day + i*one_day \n",
    "    file_path = getfile(date)\n",
    "    if False == os.path.exists(file_path) and overwrite == False:\n",
    "        k=k+1\n",
    "        print(\"Downloading file (\",i+1,\"/\",N,\"): \",tostr(date,es_fmt),end=\"\\r\")\n",
    "        url = 'https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-regioni/'\\\n",
    "        +root_reg+tostr(date,github_fmt)+\".csv\"\n",
    "        # i valori sono interi\n",
    "        df  = pd.read_csv(url)\n",
    "        df = dropdata(df)\n",
    "        df.to_csv(file_path,index=False)\n",
    "print(\"\\nDone (downloaded file: \",k,\")\")\n",
    "print(\"Folder size : \",get_size(directory,\"Kb\"),\" Kb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe di esempio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(getfile(today))\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df[\"denominazione_regione\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serie storiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/date-time-types-in-pandas-python/customize-dates-matplotlib-plots-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ 'ricoverati_con_sintomi' , 'terapia_intensiva' , \\\n",
    "        'totale_ospedalizzati', 'isolamento_domiciliare', 'totale_positivi',\\\n",
    "        'variazione_totale_positivi', 'nuovi_positivi', 'dimessi_guariti',\\\n",
    "        'deceduti', 'casi_da_sospetto_diagnostico', 'casi_da_screening',\\\n",
    "        'totale_casi', 'tamponi', 'casi_testati']# + 'denominazione_regione'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# per ogni variabile creo un file con:\n",
    "# colonne : data, tutte le regioni\n",
    "# righe   : date\n",
    "overwrite = False\n",
    "\n",
    "# ciclo sulle variabili\n",
    "N = (today - first_day).days\n",
    "k=0\n",
    "for c in cols:\n",
    "    #\n",
    "    print(k+1,\"/\",len(cols),\"(\",c,\")\",end=\"\\r\")\n",
    "    # nome del file contenente il dataframe\n",
    "    outname = c + \".csv\" \n",
    "    outdir  = data_dir + reg_dir + time_series_dir\n",
    "    file_time_series = os.path.join(outdir, outname)  \n",
    "    #file_time_series = data_dir + reg_dir + time_series_dir + c + \".csv\"\n",
    "    # controllo se ho già creato questo file\n",
    "    if os.path.exists(file_time_series) is True and overwrite is False :\n",
    "        #print(\"Read\")\n",
    "        # in caso affermativo lo leggo e lo agggiorno\n",
    "        time_series = pd.read_csv(file_time_series)\n",
    "        time_series.set_index(\"Data\",inplace=True,drop=False)\n",
    "    else:\n",
    "        # in caso negativo creo da zero il dataframe\n",
    "        time_series = pd.DataFrame()\n",
    "        time_series[\"Data\"] = []\n",
    "        for i in lista_reg:\n",
    "            time_series[i] = []\n",
    "        time_series.set_index(\"Data\",inplace=True,drop=False)\n",
    "\n",
    "    # ciclo su tutte le date (mancanti) ed inserisco i dati\n",
    "    stampa_primo = False\n",
    "    for i in range(N+1):\n",
    "        #\n",
    "        date = first_day + i * one_day\n",
    "        date_str = tostr(date, es_fmt)\n",
    "        #\n",
    "        if stampa_primo is True :\n",
    "            string = str(k+1)+\"/\"+str(len(cols))+\" (\"+ str(c)+\") | date (\"+str(i+1)+\"/\"+str(N)+\"): \"+date_str+\"    \"# \\\n",
    "            #+str(S)+str(stampa_primo)\n",
    "            print(string,end=\"\\r\",flush=True)                \n",
    "        \n",
    "        # cerco se ho già la data\n",
    "        if date_str in time_series[\"Data\"] and overwrite is True:\n",
    "            time_series = time_series.drop(date_str)\n",
    "        #\n",
    "        if date_str not in time_series[\"Data\"] or overwrite is True:\n",
    "            #if stampa_primo is False :\n",
    "            stampa_primo = True\n",
    "            #S = i\n",
    "            #print(\"ciao\")\n",
    "            file_path = getfile(date)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.set_index(\"denominazione_regione\")\n",
    "            # aggiungo la data\n",
    "            append = {\"Data\": date_str }\n",
    "            for j in lista_reg :\n",
    "                 append[j] = df[c][lista_reg][j]\n",
    "            time_series = time_series.append(append,ignore_index=True)\n",
    "            # aggiungo i valori per ogni regione\n",
    "            #time_series.iloc[date_str,lista_reg] = list(df[c][lista_reg])\n",
    "            #del df\n",
    "    \n",
    "    #\n",
    "    print(\"\")\n",
    "    time_series.to_csv(file_time_series,index=False)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo di nuove serie storiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Preparazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def media_mobile(file_in,file_out,N=7):\n",
    "    #file nuovi deceduti\n",
    "    file_nuovi_deceduti = os.path.join(outdir, file_in)   \n",
    "    #leggo il dataframe\n",
    "    nuovi_deceduti      = pd.read_csv(file_nuovi_deceduti)\n",
    "    #calcolo la media mobile\n",
    "    mm_nd = nuovi_deceduti.rolling(N,min_periods=1,center=False).mean()\n",
    "    #aggiungo colonna Data\n",
    "    mm_nd[\"Data\"] = nuovi_deceduti[\"Data\"]\n",
    "    #riordino colonne\n",
    "    cols = mm_nd.columns\n",
    "    mm_nd = mm_nd[list([\"Data\"]) + list(cols)]\n",
    "    #file media mobile nuovi deceduti\n",
    "    file_mm_nd = os.path.join(outdir, file_out)   \n",
    "    #salvo su file\n",
    "    mm_nd.to_csv(file_mm_nd,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi deceduti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#file deceduti\n",
    "file_deceduti = os.path.join(outdir, \"deceduti.csv\")   \n",
    "df = pd.read_csv(file_deceduti)\n",
    "df.set_index(\"Data\",inplace=True,drop=True)\n",
    "\n",
    "#file nuovi deceduti\n",
    "file_time_series = os.path.join(outdir, \"nuovi_deceduti.csv\") \n",
    "if os.path.exists(file_time_series) == True and overwrite == False :\n",
    "    time_series = pd.read_csv(file_time_series)\n",
    "    time_series.set_index(\"Data\",inplace=True,drop=True)\n",
    "    \n",
    "    #prendo l'ultima riga\n",
    "    start = len(time_series)-1\n",
    "    \n",
    "    #aggiungo le righe mancanti\n",
    "    dfi = df.index\n",
    "    tsi = time_series.index\n",
    "    newdates = [ a for a in dfi if a not in tsi ]\n",
    "    empty = np.zeros(len(cols))\n",
    "    for nd in newdates:\n",
    "        time_series.loc[nd,:] = empty\n",
    "else :\n",
    "    time_series = df.copy()\n",
    "    \n",
    "    #copio la prima riga\n",
    "    first = df.first_valid_index()\n",
    "    time_series.loc[first] = df.loc[first]\n",
    "    start = 1\n",
    "\n",
    "#calcolo la differenza\n",
    "for i in range(start,len(df)):\n",
    "    time_series.iloc[i] = df.iloc[i] - df.iloc[i-1]\n",
    "    \n",
    "#aggiungo la data e riordino le colonne\n",
    "cols = time_series.columns\n",
    "time_series['Data'] = time_series.index\n",
    "time_series = time_series[list([\"Data\"]) + list(cols)]\n",
    "\n",
    "#salvo su file\n",
    "time_series.to_csv(file_time_series,index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Media mobile (settimanale) nuovi deceduti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "media_mobile(file_in=\"nuovi_deceduti.csv\",file_out=\"nuovi_deceduti_mm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Media mobile (settimanale) nuovi positivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "media_mobile(file_in=\"nuovi_positivi.csv\",file_out=\"nuovi_positivi_mm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi tamponi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#file tamponi\n",
    "file_tamponi = os.path.join(outdir, \"tamponi.csv\")   \n",
    "df = pd.read_csv(file_tamponi)\n",
    "df.set_index(\"Data\",inplace=True,drop=True)\n",
    "\n",
    "#file nuovi tamponi\n",
    "file_time_series = os.path.join(outdir, \"nuovi_tamponi.csv\")   \n",
    "if os.path.exists(file_time_series) is True and overwrite is False :\n",
    "    time_series = pd.read_csv(file_time_series)\n",
    "    time_series.set_index(\"Data\",inplace=True,drop=True)\n",
    "    \n",
    "    #prendo l'ultima riga\n",
    "    start = len(time_series)-1\n",
    "    \n",
    "    #aggiungo le righe mancanti\n",
    "    dfi = df.index\n",
    "    tsi = time_series.index\n",
    "    newdates = [ a for a in dfi if a not in tsi ]\n",
    "    empty = np.zeros(len(cols))\n",
    "    for nd in newdates:\n",
    "        time_series.loc[nd,:] = empty\n",
    "    \n",
    "else :\n",
    "    time_series = df.copy()\n",
    "    \n",
    "    #copio la prima riga\n",
    "    first = df.first_valid_index()\n",
    "    time_series.loc[first] = df.loc[first]\n",
    "    start = 1\n",
    "\n",
    "    \n",
    "#calcolo la differenza\n",
    "for i in range(start,len(df)):\n",
    "    time_series.iloc[i] = df.iloc[i] - df.iloc[i-1]\n",
    "\n",
    "\n",
    "#aggiungo la data e riordino le colonne\n",
    "cols = time_series.columns\n",
    "time_series['Data'] = time_series.index\n",
    "time_series = time_series[list([\"Data\"]) + list(cols)]\n",
    "\n",
    "#salvo su file\n",
    "time_series.to_csv(file_time_series,index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi tamponi (media mobile settimanale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "media_mobile(file_in=\"nuovi_tamponi.csv\",file_out=\"nuovi_tamponi_mm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Percentuale nuovi tamponi positivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#file nuovi positivi\n",
    "file_nuovi_positivi = os.path.join(outdir, \"nuovi_positivi.csv\")   \n",
    "#leggo il dataframe\n",
    "nuovi_positivi      = pd.read_csv(file_nuovi_positivi)\n",
    "nuovi_positivi.set_index(\"Data\",inplace=True,drop=True)\n",
    "\n",
    "#file nuovi tamponi\n",
    "file_tamponi = os.path.join(outdir, \"tamponi.csv\")  \n",
    "#leggo il dataframe\n",
    "nuovi_tamponi = pd.read_csv(file_tamponi)\n",
    "nuovi_tamponi.set_index(\"Data\",inplace=True,drop=True)\n",
    "#percentuale nuovi tamponi positivi\n",
    "pntp = 100 * nuovi_positivi / nuovi_tamponi\n",
    "#aggiungo colonna Data e riordino colonne\n",
    "cols = pntp.columns\n",
    "pntp[\"Data\"] = nuovi_tamponi.index\n",
    "pntp = pntp[list([\"Data\"]) + list(cols)]\n",
    "#file percentuale nuovi tamponi positivi\n",
    "file_pntp = os.path.join(outdir, \"perc_nuovi_tamponi_positivi.csv\")   \n",
    "#salvo su file\n",
    "pntp.to_csv(file_pntp,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Percentuale nuovi tamponi positivi (media mobile settimanale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "media_mobile(file_in=\"perc_nuovi_tamponi_positivi.csv\",file_out=\"perc_nuovi_tamponi_positivi_mm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confronto regioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs  = [\"Piemonte\",\"Lombardia\",\"Veneto\",\"Lazio\",\"Campania\",'Emilia-Romagna','Campania','Puglia','Sicilia']\n",
    "#lista_reg\n",
    "regs_nord = ['Friuli Venezia Giulia','Liguria', 'Lombardia','P.A. Bolzano', 'P.A. Trento', \\\n",
    "             'Piemonte','Valle d\\'Aosta', 'Veneto']\n",
    "regs_centro = ['Abruzzo','Emilia-Romagna','Lazio','Marche','Molise','Toscana', 'Umbria']\n",
    "regs_sud = ['Basilicata', 'Calabria', 'Campania','Puglia','Sardegna', 'Sicilia']\n",
    "#lista_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plt_time_series(var,regs,title,xmin=None):\n",
    "    outname = var + \".csv\" \n",
    "    outdir  = data_dir + reg_dir + time_series_dir\n",
    "    file_time_series = os.path.join(outdir, outname) \n",
    "\n",
    "    #\n",
    "    ts = pd.read_csv(file_time_series)\n",
    "    \n",
    "    #\n",
    "    if xmin is not None :\n",
    "        ts = ts[ts[\"Data\"] >= xmin]\n",
    "    \n",
    "    #\n",
    "    xticks = [ i for i in ts[\"Data\"] if datetime.datetime.strptime(i,es_fmt).day == 1 ]\n",
    "    xlabel = [ datetime.datetime.strftime(datetime.datetime.strptime(i,es_fmt),plt_fmt) for i in xticks ]\n",
    "\n",
    "    #\n",
    "    fig, ax = plt.subplots(figsize=(15, 5)) #plt.figure()\n",
    "    for r in regs :\n",
    "        plt.plot(ts[\"Data\"],ts[r],label=r)\n",
    "\n",
    "    plt.xticks(ticks=xticks,labels=xlabel,rotation=45)\n",
    "    #plt.legend(loc=\"upper center\")\n",
    "    plt.legend(loc=\"upper left\",bbox_to_anchor= (1, 1))\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Totale positivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_time_series( var= \"totale_positivi\",regs=regs,title = \"Totale positivi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"totale_positivi\",\\\n",
    "                regs=regs_nord,title = \"Totale positivi (Nord)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"totale_positivi\",\\\n",
    "                regs=regs_centro,title = \"Totale positivi (Centro)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"totale_positivi\",\\\n",
    "                regs=regs_sud,title = \"Totale positivi (Sud)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi positivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"nuovi_positivi\",regs=regs,title = \"Nuovi positivi\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi positivi (media mobile settimanale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"nuovi_positivi_mm\",regs=regs,title = \"Nuovi positivi (media mobile settimanale)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Terapie intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"terapia_intensiva\",regs=regs,title = \"Terapie intensive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi deceduti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"nuovi_deceduti\",regs=regs,title = \"Nuovi deceduti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi deceduti (media mobile settimanale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"nuovi_deceduti_mm\",regs=regs,title = \"Nuovi deceduti (media mobile settimanale)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi tamponi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"nuovi_tamponi\",regs=regs,title = \"Nuovi tamponi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Nuovi tamponi (media mobile settimanale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"nuovi_tamponi_mm\",regs=regs,title = \"Nuovi tamponi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Percentuale nuovi tamponi positivi (media mobile settimanale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt_time_series( var= \"perc_nuovi_tamponi_positivi_mm\",\\\n",
    "                regs=regs,title = \"Percentuale nuovi tamponi positivi\",\\\n",
    "               xmin=\"2020-10-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Province"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Preparazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "https://pymotw.com/2/datetime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "lista_reg = list( [ 'Abruzzo', 'Basilicata', 'Calabria', 'Campania', 'Emilia-Romagna', 'Friuli Venezia Giulia', 'Lazio', \\\n",
    "             'Liguria', 'Lombardia', 'Marche', 'Molise', 'P.A. Bolzano', 'P.A. Trento', 'Piemonte', 'Puglia', \\\n",
    "             'Sardegna', 'Sicilia', 'Toscana', 'Umbria', \"Valle d'Aosta\", 'Veneto' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# impostazione per sovrascrivere i file\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "directory = data_dir + prov_dir + raw_dir\n",
    "\n",
    "#\n",
    "N = (today - first_day).days\n",
    "k=0\n",
    "for i in range(N):\n",
    "    date      = first_day + i*one_day \n",
    "    file_path = getfile(date)\n",
    "    if False == os.path.exists(file_path) and overwrite == False:\n",
    "        k=k+1\n",
    "        print(\"Downloading file (\",i+1,\"/\",N,\"): \",tostr(date,es_fmt),end=\"\\r\")\n",
    "        url = 'https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-province/'\\\n",
    "        +root_prov+tostr(date,github_fmt)+\".csv\"\n",
    "        # i valori sono interi\n",
    "        df  = pd.read_csv(url)\n",
    "        df = dropdata(df)\n",
    "        df.to_csv(file_path,index=False)\n",
    "print(\"\\nDone (downloaded file: \",k,\")\")\n",
    "print(\"Folder size : \",get_size(directory,\"Kb\"),\" Kb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Dataframe di esempio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(getfile(first_day))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "print(list(df[\"denominazione_provincia\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "a = list(np.unique(list(df[\"denominazione_provincia\"])))\n",
    "a.remove(\"In fase di definizione/aggiornamento\")\n",
    "#a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Serie storiche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "https://www.earthdatascience.org/courses/use-data-open-source-python/use-time-series-data-in-python/date-time-types-in-pandas-python/customize-dates-matplotlib-plots-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "cols = [ 'ricoverati_con_sintomi' , 'terapia_intensiva' , \\\n",
    "        'totale_ospedalizzati', 'isolamento_domiciliare', 'totale_positivi',\\\n",
    "        'variazione_totale_positivi', 'nuovi_positivi', 'dimessi_guariti',\\\n",
    "        'deceduti', 'casi_da_sospetto_diagnostico', 'casi_da_screening',\\\n",
    "        'totale_casi', 'tamponi', 'casi_testati']# + 'denominazione_regione'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# per ogni variabile creo un file con:\n",
    "# colonne : data, tutte le regioni\n",
    "# righe   : date\n",
    "overwrite = False\n",
    "\n",
    "# ciclo sulle variabili\n",
    "N = (today - first_day).days\n",
    "k=0\n",
    "for c in cols:\n",
    "    #\n",
    "    print(k+1,\"/\",len(cols),\"(\",c,\")\",end=\"\\r\")\n",
    "    # nome del file contenente il dataframe\n",
    "    outname = c + \".csv\" \n",
    "    outdir  = data_dir + reg_dir + time_series_dir\n",
    "    file_time_series = os.path.join(outdir, outname)  \n",
    "    #file_time_series = data_dir + reg_dir + time_series_dir + c + \".csv\"\n",
    "    # controllo se ho già creato questo file\n",
    "    if os.path.exists(file_time_series) is True and overwrite is False :\n",
    "        #print(\"Read\")\n",
    "        # in caso affermativo lo leggo e lo agggiorno\n",
    "        time_series = pd.read_csv(file_time_series)\n",
    "        time_series.set_index(\"Data\",inplace=True,drop=False)\n",
    "    else:\n",
    "        # in caso negativo creo da zero il dataframe\n",
    "        time_series = pd.DataFrame()\n",
    "        time_series[\"Data\"] = []\n",
    "        for i in lista_reg:\n",
    "            time_series[i] = []\n",
    "        time_series.set_index(\"Data\",inplace=True,drop=False)\n",
    "\n",
    "    # ciclo su tutte le date (mancanti) ed inserisco i dati\n",
    "    stampa_primo = False\n",
    "    for i in range(N):\n",
    "        #\n",
    "        date = first_day + i * one_day\n",
    "        date_str = tostr(date, es_fmt)\n",
    "        #\n",
    "        if stampa_primo is True :\n",
    "            string = str(k+1)+\"/\"+str(len(cols))+\" (\"+ str(c)+\") | date (\"+str(i+1)+\"/\"+str(N)+\"): \"+date_str+\"    \"# \\\n",
    "            #+str(S)+str(stampa_primo)\n",
    "            print(string,end=\"\\r\",flush=True)                \n",
    "        \n",
    "        # cerco se ho già la data\n",
    "        if date_str in time_series[\"Data\"] and overwrite is True:\n",
    "            time_series = time_series.drop(date_str)\n",
    "        #\n",
    "        if date_str not in time_series[\"Data\"] or overwrite is True:\n",
    "            #if stampa_primo is False :\n",
    "            stampa_primo = True\n",
    "            #S = i\n",
    "            #print(\"ciao\")\n",
    "            file_path = getfile(date)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.set_index(\"denominazione_regione\")\n",
    "            # aggiungo la data\n",
    "            append = {\"Data\": date_str }\n",
    "            for j in lista_reg :\n",
    "                 append[j] = df[c][lista_reg][j]\n",
    "            time_series = time_series.append(append,ignore_index=True)\n",
    "            # aggiungo i valori per ogni regione\n",
    "            #time_series.iloc[date_str,lista_reg] = list(df[c][lista_reg])\n",
    "            #del df\n",
    "    \n",
    "    #\n",
    "    print(\"\")\n",
    "    time_series.to_csv(file_time_series,index=False)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
